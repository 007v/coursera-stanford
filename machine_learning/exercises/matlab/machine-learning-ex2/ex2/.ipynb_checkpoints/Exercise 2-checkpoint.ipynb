{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 2.ipynb\n",
      "costFunction.m\n",
      "costFunctionReg.m\n",
      "ex2.m\n",
      "ex2_reg.m\n",
      "ex2data1.txt\n",
      "ex2data2.txt\n",
      "lib\n",
      "mapFeature.m\n",
      "plotData.m\n",
      "plotDecisionBoundary.m\n",
      "predict.m\n",
      "sigmoid.m\n",
      "submit.m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) ex2.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load ex2.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class - Exercise 2: Logistic Regression\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the logistic\n",
    "%  regression exercise. You will need to complete the following functions \n",
    "%  in this exericse:\n",
    "%\n",
    "%     sigmoid.m\n",
    "%     costFunction.m\n",
    "%     predict.m\n",
    "%     costFunctionReg.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc\n",
    "\n",
    "%% Load Data\n",
    "%  The first two columns contains the exam scores and the third column\n",
    "%  contains the label.\n",
    "\n",
    "data = load('ex2data1.txt');\n",
    "X = data(:, [1, 2]); y = data(:, 3);\n",
    "\n",
    "%% ==================== Part 1: Plotting ====================\n",
    "%  We start the exercise by first plotting the data to understand the \n",
    "%  the problem we are working with.\n",
    "\n",
    "fprintf(['Plotting data with + indicating (y = 1) examples and o ' ...\n",
    "         'indicating (y = 0) examples.\\n']);\n",
    "\n",
    "plotData(X, y);\n",
    "\n",
    "% Put some labels \n",
    "hold on;\n",
    "% Labels and Legend\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "\n",
    "% Specified in plot order\n",
    "legend('Admitted', 'Not admitted')\n",
    "hold off;\n",
    "\n",
    "fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "\n",
    "%% ============ Part 2: Compute Cost and Gradient ============\n",
    "%  In this part of the exercise, you will implement the cost and gradient\n",
    "%  for logistic regression. You neeed to complete the code in \n",
    "%  costFunction.m\n",
    "\n",
    "%  Setup the data matrix appropriately, and add ones for the intercept term\n",
    "[m, n] = size(X);\n",
    "\n",
    "% Add intercept term to x and X_test\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% Initialize fitting parameters\n",
    "initial_theta = zeros(n + 1, 1);\n",
    "\n",
    "% Compute and display initial cost and gradient\n",
    "[cost, grad] = costFunction(initial_theta, X, y);\n",
    "\n",
    "fprintf('Cost at initial theta (zeros): %f\\n', cost);\n",
    "fprintf('Gradient at initial theta (zeros): \\n');\n",
    "fprintf(' %f \\n', grad);\n",
    "\n",
    "fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "\n",
    "%% ============= Part 3: Optimizing using fminunc  =============\n",
    "%  In this exercise, you will use a built-in function (fminunc) to find the\n",
    "%  optimal parameters theta.\n",
    "\n",
    "%  Set options for fminunc\n",
    "options = optimset('GradObj', 'on', 'MaxIter', 400);\n",
    "\n",
    "%  Run fminunc to obtain the optimal theta\n",
    "%  This function will return theta and the cost \n",
    "[theta, cost] = ...\n",
    "\tfminunc(@(t)(costFunction(t, X, y)), initial_theta, options);\n",
    "\n",
    "% Print theta to screen\n",
    "fprintf('Cost at theta found by fminunc: %f\\n', cost);\n",
    "fprintf('theta: \\n');\n",
    "fprintf(' %f \\n', theta);\n",
    "\n",
    "% Plot Boundary\n",
    "plotDecisionBoundary(theta, X, y);\n",
    "\n",
    "% Put some labels \n",
    "hold on;\n",
    "% Labels and Legend\n",
    "xlabel('Exam 1 score')\n",
    "ylabel('Exam 2 score')\n",
    "\n",
    "% Specified in plot order\n",
    "legend('Admitted', 'Not admitted')\n",
    "hold off;\n",
    "\n",
    "fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "%% ============== Part 4: Predict and Accuracies ==============\n",
    "%  After learning the parameters, you'll like to use it to predict the outcomes\n",
    "%  on unseen data. In this part, you will use the logistic regression model\n",
    "%  to predict the probability that a student with score 45 on exam 1 and \n",
    "%  score 85 on exam 2 will be admitted.\n",
    "%\n",
    "%  Furthermore, you will compute the training and test set accuracies of \n",
    "%  our model.\n",
    "%\n",
    "%  Your task is to complete the code in predict.m\n",
    "\n",
    "%  Predict probability for a student with score 45 on exam 1 \n",
    "%  and score 85 on exam 2 \n",
    "\n",
    "prob = sigmoid([1 45 85] * theta);\n",
    "fprintf(['For a student with scores 45 and 85, we predict an admission ' ...\n",
    "         'probability of %f\\n\\n'], prob);\n",
    "\n",
    "% Compute accuracy on our training set\n",
    "p = predict(theta, X);\n",
    "\n",
    "fprintf('Train Accuracy: %f\\n', mean(double(p == y)) * 100);\n",
    "\n",
    "fprintf('\\nProgram paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Solution of ex2.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave_kernel"
  },
  "language_info": {
   "codemirror_mode": "Octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
